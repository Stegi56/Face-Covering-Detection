{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyOvtopNMSGu0wJ6rUiODQm4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from skimage.feature import hog\n","from skimage import img_as_ubyte, color, io, exposure,transform\n","from skimage.transform import resize\n","from joblib import load\n","from matplotlib import patches\n","import matplotlib.pyplot as plt\n","import cv2\n","import numpy as np\n","import random"],"metadata":{"id":"CHa2nB5JEOAV","executionInfo":{"status":"ok","timestamp":1745671715861,"user_tz":-60,"elapsed":3,"user":{"displayName":"Joelis Staugaitis","userId":"07502770248124587248"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["import os\n","os.environ[\"OPENCV_ENABLE_NONFREE\"] = \"1\"\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'Colab Notebooks/Face Covering Detection'\n","GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","\n","print(os.listdir(GOOGLE_DRIVE_PATH))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DGa5FfmCEdQe","executionInfo":{"status":"ok","timestamp":1745670933323,"user_tz":-60,"elapsed":1520,"user":{"displayName":"Joelis Staugaitis","userId":"07502770248124587248"}},"outputId":"1a811d94-e2de-4d42-b927-1976c2d0656a"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","['CV2024_CW_Dataset.zip', 'CV2024_CW_Dataset', 'Wild dataset', 'code.pdf', 'Models', 'Face Covering Detection.ipynb', ' test_function.ipynb']\n"]}]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1LZueCGE_DQRZIboyno0gtDAnNCPt5Aus"},"id":"dkjsaucQDD9p","executionInfo":{"status":"ok","timestamp":1745676603338,"user_tz":-60,"elapsed":65025,"user":{"displayName":"Joelis Staugaitis","userId":"07502770248124587248"}},"outputId":"e46bf403-0708-4716-fa70-ec1f14b0009b"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["path = os.path.join(GOOGLE_DRIVE_PATH, 'Personal Dataset')\n","\n","!cp -r '{path}' .\n","\n","def MaskDetection(path):\n","\n","  photos = []\n","\n","  for image in os.listdir(os.path.join('Personal Dataset')):\n","    if os.path.isfile(os.path.join('Personal Dataset', image)):\n","      img = io.imread(os.path.join('Personal Dataset', image))\n","      photos.append(img)\n","\n","  while len(photos) > 4:\n","    del photos[random.randint(0, len(photos)-1)]\n","\n","  classifier = load(os.path.join(GOOGLE_DRIVE_PATH, 'Models', 'HOG_SVM.joblib'))\n","\n","  def extract_and_resize(img, face_coord, out_shape):\n","      x, y, w, h = face_coord\n","      face = img[y : y + h, x : x + w]\n","      face_resized = transform.resize(face, out_shape, anti_aliasing=True)\n","      return face_resized\n","\n","  for img in photos:\n","    #select faces ref lab 5\n","    fig1, ax1 = plt.subplots(figsize=(64, 64))\n","\n","    img_gray = color.rgb2gray(img)\n","    img_gray = img_as_ubyte(img_gray)\n","\n","    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n","    faces_coordinates = face_cascade.detectMultiScale(img_gray, 1.05, 25)\n","\n","    ax1.imshow(img), ax1.set_axis_off()\n","\n","    #extract faces\n","    faces = []\n","    i=0\n","    for coord in faces_coordinates:\n","      faces.append(extract_and_resize(img, coord, out_shape=(128, 128)))\n","\n","    #extract hogs\n","    fig2, ax2 = plt.subplots(1,len(faces) * 2, figsize=(64, 1))\n","    des_list = []\n","    i=0\n","    for face in faces:\n","      HOG_des, HOG_image = hog(face, orientations=8, pixels_per_cell=(6, 6),\n","                      cells_per_block=(8, 8), visualize=True, channel_axis=2)\n","\n","      HOG_image_rescaled = exposure.rescale_intensity(HOG_image, in_range=(0, 15))\n","      des_list.append(HOG_des)\n","\n","      ax2[i*2].imshow(faces[i])\n","      ax2[i*2].set_axis_off()\n","\n","      ax2[(i*2) + 1].set_axis_off()\n","      ax2[(i*2) + 1].imshow(HOG_image_rescaled, cmap='gray')\n","      i += 1\n","\n","    hog_features = np.vstack(des_list)\n","\n","    #predict faces\n","    predictions = classifier.predict(hog_features)\n","\n","    def label_face(face, colour):\n","      ax1.add_patch(\n","      patches.Rectangle(xy=(face[0], face[1]), width=face[2], height=face[3],\n","                        fill=False, color=colour, linewidth=12))\n","\n","    #label faces\n","    for face, prediction in zip(faces_coordinates, predictions):\n","      if prediction == \"good mask\":\n","        label_face(face, 'g')\n","      elif prediction == \"bad mask\":\n","        label_face(face, 'orange')\n","      else:\n","        label_face(face, 'r')\n","\n","    fig1.tight_layout\n","    fig2.tight_layout\n","    plt.show()\n","\n","MaskDetection(path)"]}]}